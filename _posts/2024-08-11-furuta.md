---
layout: post
title: Real-life Reinforcement Learning - Furuta Pendulum
subtitle: Building and training an inverted pendulum robot
thumbnail-img: /assets/img/furuta/thumb.png
share-img: /assets/img/furuta/thumb.png
category: project
tags: [SAC, reinforcement-learning, AI, robotics]
---

![](/assets/img/furuta/robot.gif)

### [Link](https://github.com/energy-in-joles/Inverted-Pendulum-Robot) to Project Repository ###

# Contents
- [Introduction](#introduction)
- [Robot Design](#robot-design)
- [Robot Environment](#robot-environment)
- [RL Model](#reinforcement-learning-model)

# Introduction
<!-- begin_excerpt -->
A few months ago, I chanced upon a [video](https://vt.tiktok.com/ZS2BTrx5T/) that demonstrated a commercial Furuta Pendulum design used to teach control theory at the University level. As someone who is always itching to try a new reinforcement learning (RL) project, this felt like the perfect challenge to apply RL to a hardware system from scratch!
<!-- end_excerpt -->

## What is it?
![explain](/assets/img/furuta/explain.jpg){: .mx-auto.d-block :}
A Furuta Pendulum is a control problem which involves a pendulum that swings in the vertical plane (as annotated with red arrows above) driven by a motor shaft in the horizontal plane (as annotated with blue arrows). The goal of the robot is to swing the pendulum to the upright vertical position (an inverted pendulum) and to keep it balanced in that position for as long as possible.

## Project Overview

This project involved building the hardware and software compoents of the robot from scratch and integrating them into one coherent system. The project can largely be split into 3 major design components:
1. **Robot Design**: The physical hardware of the robot and the Arduino code for sending the robot's raw motor and pendulum positions, while receiving and executing control instructions from the PC.
2. **Robot Environment**: The environment that the RL model interacts with to control the robot. This "middleman" between the robot and model serves to translate the raw data sent between the two to ensure that the interaction is seamless.
3. **RL Model**: The model makes the control decisions for the robot and seeks to optimise the reward calculated by the environment by continuously fine tuning its policy.

# Robot Design

## Hardware Design

![cad](/assets/img/furuta/cad.png){: .mx-auto.d-block :}

Visit my [repo](https://github.com/energy-in-joles/Inverted-Pendulum-Robot?tab=readme-ov-file#hardware-implementation) to view the parts list for this project and to see the Fusion 360 CAD design.

The hardware design for this project was fairly straightforward. The robot was essentially just a rotary encoder cleverly connected to a motor using rigid couplers and 3D printed parts. However, since this was a very complex control problem, it was important that the robot could achieve precise movements and report accurate positioning data.

#### Motor

I decided on a stepper motor, as it provides a high precision and high torque solution. A stepper motor was chosen in favor over a servo, simply due to cost (especially for a servo that can rotate 360&deg;).

An average stepper motor provides a step resolution of around 1.8&deg;. However, I set the motor on a [quarter-step](https://www.automate.org/motion-control/case-studies/what-is-the-difference-between-full-stepping-the-half-stepping-and-the-micro-drive) setting to get a step resolution of around 0.45&deg;. 

The stepper motor also allowed me to consistently return the robot to a home position. This was critical for resetting the robot environment after each training epsiode.

#### Rotary Encoder

A broad [distinction](https://www.usdigital.com/blog/difference-incremental-vs-absolute-encoders/#:~:text=An%20incremental%20encoder%20can%20only,exact%20position%20without%20any%20movement.) for rotary encoders is between incremental encoders and absolute encoders. Incremental encoders measure the change in position, rather than reporting the actual absolute position.

I found cheap high precision incremental encoders online, and decided to work with them. Incremental encoders allowed me to accurately report angular velocity (since it measures change).

However, since the absolute position of the encoder is not persistent, the encoder had to be zeroed at the vertical down position before every run. 

![quadrature](/assets/img/furuta/quadrature.png){: .mx-auto.d-block :}
__*Credit: dynapar.com (link below)*__
{: style="color:gray; font-size: 80%; text-align: center;"}

I also needed to know the direction of rotation, where I chose to use a [quadrature encoder](https://www.dynapar.com/technology/encoder_basics/quadrature_encoder/). The encoder type produces two signals (A and B), where the discrepancy between the two is used to discern the direction of rotation.

## Control

#### Motor

To control the motor, i used the [`FlexyStepper.h`](https://github.com/Stan-Reifel/FlexyStepper) header, in favor of the more well-known [`AccelStepper.h`](https://github.com/waspinator/AccelStepper) library. FlexyStepper allowed for higher velocity movement, while also giving me the flexibility to change direction rapidly.

Initially, I planned to allow the motor to rotate 360&deg;. However, I found it added a lot more complications and that the commercial Furuta Pendulum had set a restricted range of motion. I settled on a range of motion of 180&deg; for the robot in the end.

#### Rotary Encoder

To read the outpt from the encoder, I initially tried to write a simple script that used interrupts for each pulse sent from the encoder. However, the script gave noisy, unreliable and inconsistent readings.

![fsm](/assets/img/furuta/fsm.png){: .mx-auto.d-block :}
__*Credit: doublejumpelectric.com (link below)*__
{: style="color:gray; font-size: 80%; text-align: center;"}

Searching online, I found the [`Encoder.h`](https://github.com/PaulStoffregen/Encoder/tree/master) library that reads the encoder output as a [finite state machine](https://www.doublejumpelectric.com/notes/embedded/rotary_encoder/rotary_encoder/index.html). This change in code had a significant impact on the readings, where they were now highly reliable and consistent.

As the encoder I used was rated 600 pulses per revolution (PPR), which would give a resolution of around 1.6&deg; per pulse. With the new encoder library, each transition between states registered a change of 1 to the encoder reading. Since the encoder has 4 states, the encoder actually gave a raw increment of 2400 per revolution, allowing us to accurately achieve a resolution of around 0.4&deg; per increment!

## Communication

The Arduino microcontroller on the robot communicates with the PC using the default Arduino micro-USB cable provided. The robot is required to send raw motor and encoder position, while it needs to receive the desired motor acceleration input from the PC.

When sending the encoder position, I could not just send the wrapped value for each revolution (ie reporting 1 instead of 2401, where 2400 is a complete revolution). This is because our control system is also interested in velocity, which needs to compare the position from the last frame to this frame.

#### Output Buffer

![bit_shift](/assets/img/furuta/bit_shift.png){: .mx-auto.d-block :}

As the robot needs to communicate very quickly, I economised the output buffer size to be 4 bytes. I used bit shifiting to achieve this, where the bit allocation can be seen above.

```c
// prepare output buffer to send position and loop index data to python script
// buffer: 22 bits for encoder position (little endian), 12 bits for stepper pos
void update_output_buffer(byte *outputBuffer, long encoderPos, int currentStepperPos) {
  outputBuffer[0] = (encoderPos >> 0) & 0xFF;
  outputBuffer[1] = (encoderPos >> 8) & 0xFF;
  outputBuffer[2] = (encoderPos >> 14) & 0xFC | (currentStepperPos >> 10) & 0x03; // get MSB
  outputBuffer[3] = (currentStepperPos >> 0) &0xFF;
}
```

As I restricted the motor position to be between -300 to 300 steps (180&deg; motion range at quarter-step), I knew that I only required 12 bits to fully represent this range. Since the encoder position value is large, I allocated the remaining 6 bits in the motor position buffer to store more encoder position data.

#### Input Buffer

The input command was the acceleration value of the motor, which was bounded between -20k to 20k. This could be represented fully within 2 bytes of data.

#### Resetting


**Encoder Reset**: As discussed above, the encoder position value is very large and can technically keep going to infinity provided the pendulum is swung constantly. Hence, an encoder reset command was implemented. 

This was done by sending an input command value larger than 20k (32766). On receiving this command, the encoder would halt for 20 seconds to allow the pendulum to come to rest, before resetting the encoder to 0.

**Motor Reset**: After each episode ends, the motor position must be reset back to the original 0 position in preparation for the next training run. Hence, similar to the encoder reset, a command input value was defined (32767), triggering the robot to reset its motor position.



# Robot Environment

The environment 

# RL Model